{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GW only (HQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_config = '''\n",
    "out_dir: {out_dir}\n",
    "metric_best: auto\n",
    "metric_agg: argmin\n",
    "device: 'cuda:0'\n",
    "wandb:\n",
    "  use: True\n",
    "  project: {wandb_proj_name}\n",
    "  entity: <WANDB_USERNAME>\n",
    "dataset:\n",
    "  format: PyG\n",
    "  name: QM9-TL\n",
    "  dir: {ds_download_dir}\n",
    "  onehot: True\n",
    "  add_3d: False\n",
    "  target_name: {target}\n",
    "  hq_or_lq: {hq_or_lq}\n",
    "  inductive_or_transductive: {ind_or_trans}\n",
    "  task: graph\n",
    "  task_type: regression\n",
    "  transductive: False\n",
    "  node_encoder: True\n",
    "  node_encoder_name: LinearNode+RWSE\n",
    "  node_encoder_num_types: 28\n",
    "  node_encoder_bn: False\n",
    "  edge_encoder: True\n",
    "  edge_encoder_name: LinearEdge\n",
    "  edge_encoder_bn: False\n",
    "posenc_RWSE:\n",
    "  enable: True\n",
    "  kernel:\n",
    "    times_func: range(1,21)\n",
    "  model: Linear\n",
    "  dim_pe: 28\n",
    "  raw_norm_type: BatchNorm\n",
    "train:\n",
    "  mode: custom\n",
    "  batch_size: {batch_size}\n",
    "  eval_period: 1\n",
    "  ckpt_period: 100\n",
    "model:\n",
    "  type: GPSModel\n",
    "  loss_fun: l1\n",
    "  graph_pooling: mean\n",
    "  edge_decoding: dot\n",
    "gt:\n",
    "  layer_type: CustomGatedGCN+Transformer\n",
    "  layers: {num_layers}\n",
    "  n_heads: {num_heads}\n",
    "  dim_hidden: {dim_hidden}  # `gt.dim_hidden` must match `gnn.dim_inner`\n",
    "  dropout: 0.0\n",
    "  attn_dropout: 0.1\n",
    "  layer_norm: True\n",
    "  batch_norm: False\n",
    "gnn:\n",
    "  head: default\n",
    "  layers_pre_mp: 0\n",
    "  layers_post_mp: 3  # Not used when `gnn.head: san_graph`\n",
    "  dim_inner: {dim_hidden}  # `gt.dim_hidden` must match `gnn.dim_inner`\n",
    "  batchnorm: True\n",
    "  act: gelu\n",
    "  dropout: 0.0\n",
    "optim:\n",
    "  clip_grad_norm: True\n",
    "  optimizer: adamW\n",
    "  weight_decay: 1e-10\n",
    "  base_lr: 0.0005\n",
    "  max_epoch: 500\n",
    "  scheduler: reduce_on_plateau\n",
    "  reduce_factor: 0.5\n",
    "  schedule_patience: 7\n",
    "  min_lr: 1e-5\n",
    "  early_stopping_patience: 15\n",
    "share:\n",
    "  dim_in: {dim_hidden}\n",
    "  dim_out: 1\n",
    "seed: {seed}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['homo_gw', 'lumo_gw']:\n",
    "    for dim_hidden in [128, 256, 512]:\n",
    "        for num_layers in [4, 6, 8, 10]:\n",
    "            for num_heads in [8, 16]:\n",
    "\n",
    "                for seed in [0]:\n",
    "                    CONFIG_PATH = '<YOUR_PATH>/training_configs_GW_only'\n",
    "                    SCRIPT_PATH = '<YOUR_PATH>/training_scripts_GW_only'\n",
    "\n",
    "                    Path(CONFIG_PATH).mkdir(exist_ok=True, parents=True)\n",
    "                    Path(SCRIPT_PATH).mkdir(exist_ok=True, parents=True)\n",
    "                \n",
    "                    dl_dir = f'<DL_PATH>/data_QM9_TF_3D_PyG/with_edge_index/'\n",
    "                    out_dir = f'<OUT_PATH>/transfer_learning/GW_only/{target}/{seed}/{dim_hidden}/{num_layers}/{num_heads}'\n",
    "                    wandb_proj_name = '<WANDB_PROJ>'\n",
    "\n",
    "                    conf = template_config.format(\n",
    "                        target=target, hq_or_lq=\"hq\", ind_or_trans=None, seed=seed, out_dir=out_dir, dim_hidden=dim_hidden,\n",
    "                        num_layers=num_layers, num_heads=num_heads, ds_download_dir=dl_dir, wandb_proj_name=wandb_proj_name,\n",
    "                        batch_size=128,\n",
    "                    )\n",
    "                    with open(os.path.join(CONFIG_PATH, f'{target}_{seed}_{dim_hidden}_{num_layers}_{num_heads}.yaml'), 'w') as f:\n",
    "                        f.write(conf)\n",
    "\n",
    "                    script = f'python <YOUR_PATH>/transfer_learning/graphgps_3d/main.py --cfg {CONFIG_PATH}/{target}_{seed}_{dim_hidden}_{num_layers}_{num_heads}.yaml'\n",
    "                    with open(f'{SCRIPT_PATH}/{target}_{seed}_{dim_hidden}_{num_layers}_{num_heads}.sh', 'w') as f:\n",
    "                        f.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFT only (LQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_config = '''\n",
    "out_dir: {out_dir}\n",
    "metric_best: auto\n",
    "metric_agg: argmin\n",
    "device: 'cuda:0'\n",
    "wandb:\n",
    "  use: True\n",
    "  project: {wandb_proj_name}\n",
    "  entity: <WANDB_USERNAME>\n",
    "dataset:\n",
    "  format: PyG\n",
    "  name: QM9-TL\n",
    "  dir: {ds_download_dir}\n",
    "  onehot: True\n",
    "  add_3d: False\n",
    "  target_name: {target}\n",
    "  hq_or_lq: {hq_or_lq}\n",
    "  inductive_or_transductive: {ind_or_trans}\n",
    "  task: graph\n",
    "  task_type: regression\n",
    "  transductive: False\n",
    "  node_encoder: True\n",
    "  node_encoder_name: LinearNode+RWSE\n",
    "  node_encoder_num_types: 28\n",
    "  node_encoder_bn: False\n",
    "  edge_encoder: True\n",
    "  edge_encoder_name: LinearEdge\n",
    "  edge_encoder_bn: False\n",
    "posenc_RWSE:\n",
    "  enable: True\n",
    "  kernel:\n",
    "    times_func: range(1,21)\n",
    "  model: Linear\n",
    "  dim_pe: 28\n",
    "  raw_norm_type: BatchNorm\n",
    "train:\n",
    "  mode: custom\n",
    "  batch_size: {batch_size}\n",
    "  eval_period: 1\n",
    "  ckpt_period: 25\n",
    "model:\n",
    "  type: GPSModel\n",
    "  loss_fun: l1\n",
    "  graph_pooling: mean\n",
    "  edge_decoding: dot\n",
    "gt:\n",
    "  layer_type: CustomGatedGCN+Transformer\n",
    "  layers: {num_layers}\n",
    "  n_heads: {num_heads}\n",
    "  dim_hidden: {dim_hidden}  # `gt.dim_hidden` must match `gnn.dim_inner`\n",
    "  dropout: 0.0\n",
    "  attn_dropout: 0.1\n",
    "  layer_norm: True\n",
    "  batch_norm: False\n",
    "gnn:\n",
    "  head: default\n",
    "  layers_pre_mp: 0\n",
    "  layers_post_mp: 3  # Not used when `gnn.head: san_graph`\n",
    "  dim_inner: {dim_hidden}  # `gt.dim_hidden` must match `gnn.dim_inner`\n",
    "  batchnorm: True\n",
    "  act: gelu\n",
    "  dropout: 0.0\n",
    "optim:\n",
    "  clip_grad_norm: True\n",
    "  optimizer: adamW\n",
    "  weight_decay: 1e-10\n",
    "  base_lr: 0.0005\n",
    "  max_epoch: 151\n",
    "share:\n",
    "  dim_in: {dim_hidden}\n",
    "  dim_out: 1\n",
    "seed: {seed}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the checkpoint saving frequency above is set to 25, such that we don't save every one of the 150 checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['homo_dft', 'lumo_dft']:\n",
    "    for dim_hidden in [256]:\n",
    "        for num_layers in [8]:\n",
    "            for num_heads in [16]:\n",
    "                for ind_or_trans in ['transductive', 'inductive']:\n",
    "                    for seed in [0]:\n",
    "                        CONFIG_PATH = '<YOUR_PATH>/training_configs_DFT'\n",
    "                        SCRIPT_PATH = '<YOUR_PATH>/training_scripts_DFT'\n",
    "\n",
    "                        Path(CONFIG_PATH).mkdir(exist_ok=True, parents=True)\n",
    "                        Path(SCRIPT_PATH).mkdir(exist_ok=True, parents=True)\n",
    "                    \n",
    "                        dl_dir = f'<DL_PATH>/data_QM9_TF_3D_PyG/with_edge_index/'\n",
    "                        out_dir = f'<OUT_PATH>/transfer_learning/DFT_only/{target}/{ind_or_trans}/{seed}/{dim_hidden}/{num_layers}/{num_heads}'\n",
    "                        wandb_proj_name = '<WANDB_PROJ>'\n",
    "\n",
    "                        conf = template_config.format(\n",
    "                            target=target, hq_or_lq=\"lq\", seed=seed, out_dir=out_dir, dim_hidden=dim_hidden,\n",
    "                            num_layers=num_layers, num_heads=num_heads, ds_download_dir=dl_dir, wandb_proj_name=wandb_proj_name,\n",
    "                            batch_size=128, ind_or_trans=ind_or_trans\n",
    "                        )\n",
    "                        with open(os.path.join(CONFIG_PATH, f'{target}_{ind_or_trans}_{seed}_{dim_hidden}_{num_layers}_{num_heads}.yaml'), 'w') as f:\n",
    "                            f.write(conf)\n",
    "\n",
    "                        script = f'python <YOUR_PATH>/transfer_learning/graphgps_3d/main.py --cfg {CONFIG_PATH}/{target}_{ind_or_trans}_{seed}_{dim_hidden}_{num_layers}_{num_heads}.yaml'\n",
    "                        with open(f'{SCRIPT_PATH}/{target}_{ind_or_trans}_{seed}_{dim_hidden}_{num_layers}_{num_heads}.sh', 'w') as f:\n",
    "                            f.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain DFT to GW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_config = '''\n",
    "out_dir: {out_dir}\n",
    "metric_best: auto\n",
    "metric_agg: argmin\n",
    "device: 'cuda:0'\n",
    "wandb:\n",
    "  use: True\n",
    "  project: {wandb_proj_name}\n",
    "  entity: <WANDB_USERNAME>\n",
    "dataset:\n",
    "  format: PyG\n",
    "  name: QM9-TL\n",
    "  dir: {ds_download_dir}\n",
    "  onehot: True\n",
    "  add_3d: False\n",
    "  target_name: {target}\n",
    "  hq_or_lq: {hq_or_lq}\n",
    "  inductive_or_transductive: {ind_or_trans}\n",
    "  task: graph\n",
    "  task_type: regression\n",
    "  transductive: False\n",
    "  node_encoder: True\n",
    "  node_encoder_name: LinearNode+RWSE\n",
    "  node_encoder_num_types: 28\n",
    "  node_encoder_bn: False\n",
    "  edge_encoder: True\n",
    "  edge_encoder_name: LinearEdge\n",
    "  edge_encoder_bn: False\n",
    "posenc_RWSE:\n",
    "  enable: True\n",
    "  kernel:\n",
    "    times_func: range(1,21)\n",
    "  model: Linear\n",
    "  dim_pe: 28\n",
    "  raw_norm_type: BatchNorm\n",
    "train:\n",
    "  mode: custom\n",
    "  batch_size: {batch_size}\n",
    "  eval_period: 1\n",
    "  ckpt_period: 1\n",
    "model:\n",
    "  type: GPSModel\n",
    "  loss_fun: l1\n",
    "  graph_pooling: mean\n",
    "  edge_decoding: dot\n",
    "gt:\n",
    "  layer_type: CustomGatedGCN+Transformer\n",
    "  layers: {num_layers}\n",
    "  n_heads: {num_heads}\n",
    "  dim_hidden: {dim_hidden}  # `gt.dim_hidden` must match `gnn.dim_inner`\n",
    "  dropout: 0.0\n",
    "  attn_dropout: 0.1\n",
    "  layer_norm: True\n",
    "  batch_norm: False\n",
    "gnn:\n",
    "  head: default\n",
    "  layers_pre_mp: 0\n",
    "  layers_post_mp: 3  # Not used when `gnn.head: san_graph`\n",
    "  dim_inner: {dim_hidden}  # `gt.dim_hidden` must match `gnn.dim_inner`\n",
    "  batchnorm: True\n",
    "  act: gelu\n",
    "  dropout: 0.0\n",
    "optim:\n",
    "  clip_grad_norm: True\n",
    "  optimizer: adamW\n",
    "  weight_decay: 1e-10\n",
    "  base_lr: 0.0005\n",
    "  max_epoch: 500\n",
    "  scheduler: reduce_on_plateau\n",
    "  reduce_factor: 0.5\n",
    "  schedule_patience: 7\n",
    "  min_lr: 1e-5\n",
    "  early_stopping_patience: 15\n",
    "share:\n",
    "  dim_in: {dim_hidden}\n",
    "  dim_out: 1\n",
    "pretrained:\n",
    "  dir: {ckpt_dir}\n",
    "  reset_prediction_head: False\n",
    "  freeze_main: False\n",
    "seed: {seed}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['homo_gw']:\n",
    "    for dim_hidden in [256]:\n",
    "        for num_layers in [8]:\n",
    "            for num_heads in [16]:\n",
    "                for ind_or_trans in ['transductive', 'inductive']:\n",
    "                    for seed in [0]:\n",
    "                        CONFIG_PATH = '<YOUR_PATH>/training_configs_DFT_to_GW'\n",
    "                        SCRIPT_PATH = '<YOUR_PATH>/training_scripts_DFT_to_GW'\n",
    "\n",
    "                        Path(CONFIG_PATH).mkdir(exist_ok=True, parents=True)\n",
    "                        Path(SCRIPT_PATH).mkdir(exist_ok=True, parents=True)\n",
    "                    \n",
    "                        dl_dir = f'<DL_PATH>/data_QM9_TF_3D_PyG/with_edge_index/'\n",
    "                        out_dir = f'<OUT_PATH>/transfer_learning/DFT_to_GW/{target}/{ind_or_trans}/{seed}/{dim_hidden}/{num_layers}/{num_heads}'\n",
    "                        wandb_proj_name = '<WANDB_PROJ>'\n",
    "\n",
    "                        # Check your own\n",
    "                        ckpt_dir = f'<OUT_PATH>/transfer_learning/GW_only/homo_dft/inductive/0/256/8/16/homo_dft_inductive_0_256_8_16/'\n",
    "\n",
    "                        conf = template_config.format(\n",
    "                            target=target, hq_or_lq=\"hq\", seed=seed, out_dir=out_dir, dim_hidden=dim_hidden,\n",
    "                            num_layers=num_layers, num_heads=num_heads, ds_download_dir=dl_dir, wandb_proj_name=wandb_proj_name,\n",
    "                            batch_size=128, ind_or_trans=ind_or_trans, ckpt_dir=ckpt_dir,\n",
    "                        )\n",
    "                        with open(os.path.join(CONFIG_PATH, f'{target}_{ind_or_trans}_{seed}_{dim_hidden}_{num_layers}_{num_heads}.yaml'), 'w') as f:\n",
    "                            f.write(conf)\n",
    "\n",
    "                        script = f'python <YOUR_PATH>/transfer_learning/graphgps_3d/main.py --cfg {CONFIG_PATH}/{target}_{ind_or_trans}_{seed}_{dim_hidden}_{num_layers}_{num_heads}.yaml'\n",
    "                        with open(f'{SCRIPT_PATH}/{target}_{ind_or_trans}_{seed}_{dim_hidden}_{num_layers}_{num_heads}.sh', 'w') as f:\n",
    "                            f.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
